{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h2 align=\"center\"style=\"color: black;\">Tradeset Starter Notebook</h2>\n",
    "    <h3 align=\"center\"style=\"color: black;\">Build your Machine Learning-based Algorithmic Trading System</h3>\n",
    "    <h5 align=\"center\"style=\"color: black;\"><em>Intelligence Can Solve Complexity</em></h5>\n",
    "    <h5 align=\"center\"><a href=\"http://tradeset.ai\" style=\"color: blue;\">Tradeset.ai</a></h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll build a profitable ML-based trading system using tradeset. We will utilize the tradeset API to define a classification target for identifying upward movements of USDJPY in the Forex market and label the data accordingly. Next, we'll get ML-ready features for USDJPY, train an ML prediction model, and assess potential profits through various backtesting strategies`. At tradeset, you can do historical experiments for free! if you haven't signed up on tradeset, [sign up](http://tradeset.ai) for free and get the API key. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you need to install the __tradeset__ package using _pip_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tradeset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an API key from your [tradeset profile](http://tradeset.ai/profilesetting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# you should add your API key to your environment variables beforhand\n",
    "API_KEY = os.getenv('TRADESET_API_KEY')\n",
    "# API_KEY = \"\" # Or simply paste your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Target\n",
    "Some important assumptions and specifications of our system is as follows:\n",
    "\n",
    "|  Factor             | Specification      |\n",
    "|---------------------|--------------------|\n",
    "| Markets             | _Forex, Crypto_    |\n",
    "| Horizon             | _Intraday_         |\n",
    "| Feature Frequency      | _5 Minutes_        | \n",
    "| Problem Type        | _Classification_   |\n",
    "\n",
    "In this section you need to specify the classification problem that you are trying to solve and get the target dataframe. For example, lets say we want to train a prediction model that identifies upward movemets of 35 pips in USDJPY in the next 5 hours without downward movements of 5 pips. Using our API ypu can simply do it by `create_target`. In our Beta version of tradeset we only provide services for `USDJPY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tradeset import create_target\n",
    "\n",
    "forex_pair = 'USDJPY' # Define the forex pair for the trade\n",
    "trade_mode = 'long' # Specify the trade mode (long or short)\n",
    "target_look_ahead = 300 # Set the look-ahead period in minutes. It should be more than 5 minutes\n",
    "target_take_profit = 35 # Specify the take profit in pips\n",
    "target_stop_loss = 5 # Specify the stop loss in pips\n",
    "\n",
    "target_token, target_name = create_target(\n",
    "    forex_pair,\n",
    "    trade_mode,\n",
    "    target_look_ahead,\n",
    "    target_take_profit,\n",
    "    target_stop_loss,\n",
    "    API_KEY\n",
    "    )\n",
    "df_target = pd.read_parquet(f\"./{target_name}.parquet\")\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features\n",
    "Information Advantage is what you need to somehow predict some events of financial markets. That said, having informative features is a vital part of an ML-based algorithmic trading system. At tradeset we provide special features for each asset, making them good predictors on which you can train valuable models. Use `get_features` with `feature_type = 'train'` to get ML-ready features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-ready features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeset import get_features\n",
    "\n",
    "get_features(forex_pair, api_key = API_KEY, feature_type = 'train')\n",
    "df_features = pd.read_parquet(f\"{forex_pair}_train.parquet\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Features\n",
    "You can also get raw features which is 5-minute OHLC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features(forex_pair, api_key = API_KEY, feature_type = 'raw')\n",
    "df_raw_features = pd.read_parquet(f\"{forex_pair}_raw.parquet\")\n",
    "df_raw_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_features.merge(df_target,on=\"_time\",how=\"inner\")\n",
    "# Rename the Target column \n",
    "df_all.rename(columns={f\"{target_name}\":\"target\"},inplace=True)\n",
    "df_all.set_index(\"_time\",inplace=True)\n",
    "print(f'Min date:{df_all.index.min()} Max date:{df_all.index.max()}')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "You can do some EDA, visualize data, see correlations and do some feature engineering. But we will skip this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the field of quantitative finance, robust validation over an extended period is essential. Given the time series nature of the data, it's crucial not to shuffle during the train-test split. Introducing a gap between train and test sets (`train_test_gap_size`) is also advisable to prevent biases. To simplify this process, we've built `create_TS_cross_val_folds` and `run_model_on_folds` into the [tradeset public package](https://github.com/tradeset/tradeset-public/). However, you're free to employ your custom train-test split if preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeset import create_TS_cross_val_folds, run_model_on_folds\n",
    "\n",
    "early_stopping_rounds = None\n",
    "cross_val_config = {\n",
    "  \"n_splits\": 18, # Using 18 folds for time-series cross-validation\n",
    "  \"max_train_size\": 288 * 350, # Considering the frequency of dataset, which is 5 minutes, each day is 288 rows of data so the train size is 350 days\n",
    "  \"test_size\": 288 * 30, # The test size is 30 days\n",
    "  \"early_stopping_rounds\": early_stopping_rounds,\n",
    "  \"train_test_gap_size\": 288 * 30 , # The gap between train and test on each fold is 30 days\n",
    "}\n",
    "\n",
    "folds = create_TS_cross_val_folds(\n",
    "  df_all = df_all,\n",
    "  max_train_size = cross_val_config[\"max_train_size\"],\n",
    "  n_splits = cross_val_config[\"n_splits\"],\n",
    "  test_size = cross_val_config[\"test_size\"],\n",
    "  early_stopping_rounds = cross_val_config[\"early_stopping_rounds\"],\n",
    "  train_test_gap_size = cross_val_config[\"train_test_gap_size\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train an XGBoost model and perform cross-validation. The below parameters of the model is what we found kind of optimal during few experiments. But you can modify  these parameters and other XGBoost parameters that are not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_params =  {\n",
    "        # 'tree_method':'hist',\n",
    "        # 'device' : 'cuda',#  None,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"max_depth\": 5,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"n_estimators\": 200,\n",
    "        \"early_stopping_rounds\" : early_stopping_rounds,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"subsample\": 0.5,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"scale_pos_weight\" :1,\n",
    "        'random_state': 42,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(**xgboost_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model on Folds\n",
    "Note: the `model` in the output of `run_model_on_folds` is the model trained on the last fold which we will use for test data. This is important to use the last fold model. Beacuse unlike other domains and problems, the data drift is critical due to the changing of market dynamic. That said, we should not train the model on all historical data and instead we should optimize the amount of `max_train_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals, df_prediction, model = run_model_on_folds(\n",
    "    df = df_all,\n",
    "    folds = folds,\n",
    "    model = model,\n",
    "    early_stopping_rounds = early_stopping_rounds,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#save model\n",
    "joblib.dump(model, 'usdjpy_long_xgb.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overal_precision = df_prediction[(df_prediction.target==1)&\n",
    "                    (df_prediction.model_prediction==1)].shape[0]/df_prediction[df_prediction.model_prediction==1].shape[0]\n",
    "num_signals = df_prediction[df_prediction.model_prediction==1].shape[0]\n",
    "print(f\"Overal Precison: {overal_precision*100:.1f}%\")\n",
    "print(f\"Number of Signals: {num_signals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate profit without backtest\n",
    "If we consider a loss with the value of stop-loss for all `False Positives` (FP) signals then we will have a pessimistic estimation of profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 2\n",
    "pess_est_profit = overal_precision*num_signals*target_take_profit - (1-overal_precision)*num_signals*target_stop_loss - num_signals*spread \n",
    "print(f\"Pessimistic Estimation of Profit: {pess_est_profit:.0f} pips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But most of the times, that's not the case. This is because many FP signals are FP because they couldn't reach to the take-profit level during look-ahead period. But some of these FP signals are even profitable. Later in the notebook, we will calculate an accurate profit in the Backtest section. In the below animated GIF you can see examples of four different types of signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](target_signal_type.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (I) Using default startegy\n",
    "In this section we use the same strategy as the one used in target definition to backtest. First we need to make a dataframe containing model signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_signal = df_prediction.loc[df_prediction.model_prediction == 1]\n",
    "# ####### TEMP\n",
    "# df_model_signal.to_parquet('df_model_signal.parquet')\n",
    "# df_model_signal = pd.read_parquet('df_model_signal.parquet')\n",
    "# TEMP ########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to backtest our default strategy. we should also specify `volume` of each trade, `initial balance` and `spread`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeset import backtest_strategy\n",
    "\n",
    "strategy_config = {\n",
    "    'target_token': target_token,\n",
    "    'volume': 0.1,\n",
    "    'initial_balance': 3000,\n",
    "    'spread': 2,\n",
    "}\n",
    "backtest_results, backtest_df = backtest_strategy(df_model_signal[[\"model_prediction\"]], strategy_config, API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df.net_profit.cumsum().plot()\n",
    "backtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (II) Modify Startegy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_config_modified = {\n",
    "    'target_token': target_token,\n",
    "    'volume': 0.1,\n",
    "    'initial_balance': 3000,\n",
    "    'spread': 2,\n",
    "    \"look_ahead\": 400,\n",
    "    \"take_profit\": 40,\n",
    "    \"stop_loss\": 20,\n",
    "}\n",
    "backtest_results_modified, backtest_df_modified = backtest_strategy(df_model_signal[[\"model_prediction\"]],\n",
    "                                                                     strategy_config_modified,\n",
    "                                                                     API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df_modified.net_profit.cumsum().plot()\n",
    "backtest_results_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "These results serve as baselines and can be enhanced by developing more accurate models, employing better strategies, and refining target definitions. Now it's your opportunity to create a more profitable algorithmic trading system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "by = (pess_est_profit/strategy_config['initial_balance']*100,\n",
    "        backtest_results['profit_percent'],\n",
    "        backtest_results_modified['profit_percent'])\n",
    "bx = range(len(by))\n",
    "x_ticks_labels = ('No Backtest (pessimistic estimation)', 'Default Strategy', 'Modified Strategy')\n",
    "plt.xticks(bx, x_ticks_labels, size='small')\n",
    "plt.title('Profit Comparison')\n",
    "plt.ylabel('Profit Percent')\n",
    "plt.bar(bx,by, color = (0.1,0.1,0.7,0.6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,figsize=(5,6))\n",
    "by = (\n",
    "         backtest_results['profit_percent'],\n",
    "        backtest_results_modified['profit_percent'])\n",
    "bydd = (\n",
    "         backtest_results['max_draw_down']*-1,\n",
    "        backtest_results_modified['max_draw_down']*-1)\n",
    "bx = range(len(by))\n",
    "\n",
    "ax1.bar(bx, bydd, color=(0.7,0.2,0,0.5), width=0.35)\n",
    "ax2.bar(bx, by, color=(0.1,0.1,0.7,0.6), width = 0.35)\n",
    "x_ticks_labels = ('Default Strategy', 'Modified Strategy')\n",
    "plt.xticks(bx, x_ticks_labels, size='small')\n",
    "ax2.set_ylabel('profit percent')\n",
    "ax1.set_ylabel('maximum draw down')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Backtest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_time = [] \n",
    "signal_days = []\n",
    "for i in range(backtest_df_modified.shape[0]):\n",
    "    a = backtest_df_modified._time[i].date()\n",
    "    if a not in signal_days:\n",
    "        signal_days.append(a)\n",
    "        signal_time.append(backtest_df_modified._time[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot first 5 days of trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "idx = list(df_raw_features[df_raw_features._time.isin(signal_time)].index)\n",
    "backtest_df_modified['date'] = [d.date() for d in backtest_df_modified['_time']]\n",
    "\n",
    "for i in range(5): # to plot all days use rang(len(signal_days))\n",
    "    \n",
    "    df_plt = df_raw_features[idx[i]-5:idx[i]+288]\n",
    "                    \n",
    "    fig = go.Figure(data=[go.Candlestick(x=df_plt['_time'],\n",
    "                    open=df_plt[f'{forex_pair}_M5_OPEN'], high=df_plt[f'{forex_pair}_M5_HIGH'],\n",
    "                    low=df_plt[f'{forex_pair}_M5_LOW'], close=df_plt[f'{forex_pair}_M5_CLOSE'])\n",
    "                          ])\n",
    "    _time = signal_time[i]\n",
    "    print('date: ',_time,' weekday: ',_time.weekday())\n",
    "    print('N.o. Signals: ',backtest_df_modified[backtest_df_modified.date == _time.date()].shape[0])\n",
    "    print('day net profit: ',int(backtest_df_modified[backtest_df_modified.date == _time.date()].net_profit.sum()))\n",
    "    shapes = []\n",
    "    annotations = []\n",
    "    for _time in list(backtest_df_modified[backtest_df_modified.date == _time.date()]._time):\n",
    "        \n",
    "        shapes.append(dict(x0=_time, x1=_time, y0=0, y1=1, xref='x', yref='paper',line_width=2))\n",
    "        annotations.append(dict(x=_time, y=0.05, xref='x', yref='paper',\n",
    "            showarrow=False, xanchor='right', text=f'{int(backtest_df_modified[backtest_df_modified._time == _time].net_profit.iloc[0])}'))\n",
    "            \n",
    "    fig.update_layout(\n",
    "#         title=target_info[\"target_symbol\"],\n",
    "        shapes = shapes,\n",
    "        annotations = annotations)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Test Predictions\n",
    "For the sake of comparison, a recent subset of historical data is used for the competition. You can submit your prediction and compare your model and strategy performance with other data scientists, and see the potential results you can achieve. The results will be displayed in the `Leaderboard` section of your dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "get_features(forex_pair, api_key = API_KEY, feature_type = 'test')\n",
    "df_features_test = pd.read_parquet(f\"{forex_pair}_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model\n",
    "import joblib\n",
    "model = joblib.load('usdjpy_long_xgb.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_test[\"model_prediction\"] = model.predict(df_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = df_features_test.loc[df_features_test.model_prediction == 1][[\"model_prediction\"]]\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the baseline XGBoost model generates few signals. You can enhance it with your data science skills. As a motivation, with a single model, we could achieve up to 30% of profit for this test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeset import submit_to_leaderboard\n",
    "\n",
    "submission_strategy = {\n",
    "    'target_token': target_token,\n",
    "    'volume': 1,\n",
    "    \"look_ahead\": 480,\n",
    "    \"take_profit\": 40,\n",
    "    \"stop_loss\": 15,\n",
    "}\n",
    "submission_results, _ = submit_to_leaderboard(test_preds, submission_strategy, API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
